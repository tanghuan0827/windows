vim /etc/hosts
192.168.43.150 nn01
192.168.43.151 nn02
192.168.43.152 dn01
192.168.43.153 dn02
192.168.43.154 dn03


vim /etc/sysconfig/network
# Created by anaconda
NETWORKING=yes
HOSTNAME=nn01

建立hadoop用户
useradd hadoop
passwd hadoop

给hadoop用户赋予root用户权限
chmod u+w /etc/sudoers
hadoop ALL=NOPASSWD:ALL

su - hadoop
sudo whoami

ssh-keygen -t rsa
scp ~/.ssh/id_rsa.pub hadoop@nn02:/home/hadoop

在第二个机器nn02
mkdir -p ~/.ssh
chmod -R 700 ~/.ssh
cat id_rsa.put >> ~/.ssh/authorized_keys

创建authorized_keys
赋予权限600

回到nn01
测试
ssh nn02

============================================================
安装hadoop
tar zxvf hadoop-2.6.4.tar.gz

mv hadoop-2.6.4 hadoop

chown hadoop.hadoop hadoop

mv hadoop /usr/local

su hadoop
sudo vim ~/.bashrc
export HADOOP_HOME=/usr/local/hadoop
export HADOOP_PREFIX=$HADOOP_HOME
export HADOOP_MAPRED_HOME=$HADOOP_HOME
export HADOOP_COMMON_HOME=$HADOOP_HOME
export HADOOP_HDFS_HOME=$HADOOP_HOME
export YARN_HOME=$HADOOP_HOME
export HADOOP_COMMON_LIB_NATIVE_DIR=$HADOOP_HOME/lib/native
export PATH=$PATH:$HADOOP_HOME/sbin:$HADOOP_HOME/bin
export HADOOP_INSTALL=$HADOOP_HOME

source ~/.bashrc

vim etc/hadoop/hadoop-env.sh
export HADOOP_NAMENODE_OPTS=" -Xms1024m -Xmx1024m -XX:+UseParallelGC"
export HADOOP_DATANODE_OPTS=" -Xms1024m -Xmx1024m"
export HADOOP_LOG_DIR=/data/logs/hadoop

mkdir /data/logs
mkdir /data/logs/hadoop
chown hadoop.hadoop /data/logs/hadoop

mkdir -p /data/hadoop/hdfs/nn
mkdir -p /data/hadoop/hdfs/dn 
chown -R hadoop.hadoop /data/hadoop/hdfs/dn

hdfs namenode -format

sbin/start-dfs.sh

tail -200f /data/logs/hadoop/hadoop-hadoop-namenode-50.log

nn01:50070

scp -r /usr/local/hadoop root@nn02:/usr/local/
chown -R hadoop.hadoop /usr/local/hadoop


rm -rf /data/hadoop/hdfs/nn/current
rm -rf /data/hadoop/hdfs/dn/current

sbin/hadoop-daemon.sh --script hdfs start namenode

jps

rm -rf /data/hadoop/hdfs/dn/current

sbin/hadoop-daemon.sh --script hdfs start datanode

nn02:50070

============================================================
useradd zookeeper
passwd zookeeper

tar zxvf zookeeper-3.4.6.tar.gz
mv  zookeeper-3.4.6 /usr/local/zookeeper
chown -R zookeeper.zookeeper /usr/local/zookeeper

export ZOOKEEPER_HOME=/usr/local/zookeeper

source /etc/profile

vim conf/zoo.cfg

dataDir=/data/zookeeper
ZOO_LOG_DIR=/data/logs/zookeeper

mkdir /data/zookeeper
chown zookeeper.zookeeper /data/zookeeper
mkdir /data/logs/zookeeper
chown zookeeper.zookeeper /data/logs/zookeeper

/data/zookeeper
vim myid
1 2 3 4 5
cat 1 /data/zookeeper/myid

$ZOOKEEPER_HOME/bin/zkServer.sh start

$ZOOKEEPER_HOME/bin/zkCli.sh
ls /

bin/zkServer.sh stop
rm -rf /data/logs/zookeeper/*
rm -rf /data/zookeeper/*

vim conf/zoo.cfg

server.1=nn01:2888:3888
server.2=nn02:2888:3888
server.3=dn01:2888:3888
server.4=dn02:2888:3888
server.5=dn03:2888:3888

cd /etc/init.d

添加zookeeper的自启动项
vim zookeeper
#!/bin/bash  
#chkconfig: 2345 80 10 
#description: service zookeeper  
export    JAVA_HOME=/opt/modules/jdk1.7.0_79
export    ZOO_LOG_DIR=/data/logs/zookeeper
export    ZOOKEEPER_HOME=/usr/local/zookeeper
case  "$1"   in
          start)  su  root   ${ZOOKEEPER_HOME}/bin/zkServer.sh   start;;
          start-foreground)  su  root  ${ZOOKEEPER_HOME}/bin/zkServer.sh    start-foreground;;
          stop)  su  root   ${ZOOKEEPER_HOME}/bin/zkServer.sh   stop;;
          status)  su root  ${ZOOKEEPER_HOME}/bin/zkServer.sh    status;;
          restart)  su root   ${ZOOKEEPER_HOME}/bin/zkServer.sh   restart;;
          upgrade)su root   ${ZOOKEEPER_HOME}/bin/zkServer.sh   upgrade;;
          print-cmd)su root   ${ZOOKEEPER_HOME}/bin/zkServer.sh   print-cmd;;
          *)  echo  "requirestart|start-foreground|stop|status|restart|print-cmd";;
esac

chmod +x zookeeper
service zookeeper start

添加到自启动项
chkconfig zookeeper on

============================================================
hadoop的自动转移机制
mkdir /data/hadoop/hdfs/jn
chown hadoop.hadoop /data/hadoop/hdfs/jn

sbin/hadoop-daemon.sh start journalnode

hdfs namenode -format

nn02
hdfs namenode -bootstrapStandby

hdfs namenode -initializeSharedEdits

sbin/hadoop-daemon.sh --script hdfs start namenode

hdfs haadmin -failover nn02 nn01

bin/hdfs zkfc -formatZK

ls /

1 2
sbin/hadoop-daemon.sh --script hdfs stop namenode
sbin/hadoop-daemon.sh --script hdfs start namenode

sbin/hadoop-daemon.sh --script bin/hdfs start zkfc
jps

rm -rf /data/hadoop/hdfs/dn/*

zookeeper journalnode  namenode zkfc  datanode

============================================================
安装hbase
useradd hbase
passwd hbase

export JAVA_HOME=/usr/local/jdk1.7
export PATH=$PATH:$JAVA_HOME/bin

export HBASE_HOME=/usr/local/hbase
export PATH=$PATH:$HBASE_HOME/bin

source ~/.bashrc

`${HBASE_HOME}/bin/hbase classpath` ${HADOOP_HOME}/bin/hadoop jar ${HBASE_HOME}/lib/hbase-server-1.2.2.jar rowcounter mytable





























































